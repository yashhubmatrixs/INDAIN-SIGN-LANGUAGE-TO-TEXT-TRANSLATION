# INDAIN-SIGN-LANGUAGE-TO-TEXT-TRANSLATION
PORJECT ON REDUCING THE COMMUNICATION BARRIER BETWEEN THE NORMAL HUMAN AND THE DEAF PERSON

This project is focused on building a system that translates Indian Sign Language (ISL) gestures into text. It aims to bridge the communication gap between the hearing and speech-impaired community and those who do not understand sign language. This tool can be useful in education, customer service, and day-to-day conversations.

Features
ü§ñ Real-time ISL gesture recognition using webcam

üî§ Text output displayed for each recognized gesture

üì¶ Uses machine learning / deep learning models for hand gesture classification

üñêÔ∏è Supports static hand gestures (A-Z, 0-9 or common ISL signs)

üß† Trained on publicly available ISL datasets or custom-collected data


Technologies Used
Python

OpenCV (for image/video processing)

TensorFlow / PyTorch (for training ML model)

MediaPipe / OpenPose (optional: for hand tracking)
